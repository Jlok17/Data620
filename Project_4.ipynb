{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPq2SSVie1EJkhZAC/LWoK6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jlok17/Data620/blob/main/Project_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project 4:\n",
        "\n",
        "For this project we are looking at different classification methods to determine if we can predict if an email is going to be spam or \"Ham\" which is just a normal email. As seen below the files/folders are going to be downloaded from those website and uploaded to google drive.\n",
        "\n",
        "From there we are going to pull that data into this notebook where the files will be read and placed into a dataframe. Each Row will correspond to the text for each email as the Ham and Spam email text are going to be in separate dataframes. Following this we are going to clean all the whitespace and non-alphabetical characters and filter the words into a more distinguish characters.\n",
        "\n",
        "Once the data has been cleaned it will then be split up into a 60/40 ratio of training and testing data sets to be placed and a Naive Bayes Model. I used a 60/40 split as a higher yield in the training set for some reason overloaded my ram and caused this process to reset multiple times. Finally as we can see the results with a 90% accuracy and rate of 431 emails correctly labaled as spam, 132 incorrectly as ham when there were spam(False Positive), 26 labeled incorrectly as spam when they were ham(False Negative) and 991 that were correctly labeled as Ham.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "My data source is: [Spam/Ham Dataset](https://spamassassin.apache.org/old/publiccorpus/\n",
        ")\n",
        "\n",
        "\n",
        "> It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.\n",
        "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n"
      ],
      "metadata": {
        "id": "5WPwZM19W8RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "from pandas import DataFrame\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmh_hrMVUwE4",
        "outputId": "1e3a2463-8f74-4ac5-eb5f-e1c8b38875a9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WSmpYkvot9e",
        "outputId": "18df62e0-8058-4c34-e6ae-f9d6ef1a79b6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to your folder within your Google Drive\n",
        "folder_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# List the contents of the folder\n",
        "contents = os.listdir(folder_path)\n"
      ],
      "metadata": {
        "id": "hmZm-GELo3_X"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the \"spam_2\" folder\n",
        "folder_path = '/content/drive/MyDrive/spam_2'\n",
        "# List the files in the directory\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "num_files = len(files)\n",
        "print(\"Number of files:\", num_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgl71QS5p7YS",
        "outputId": "ae30bf7a-2107-4ee4-85f8-567eb4d49eac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files: 1397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the \"easy_ham\" folder\n",
        "folder_path2 = '/content/drive/MyDrive/easy_ham'\n",
        "# List the files in the directory\n",
        "files = os.listdir(folder_path2)\n",
        "\n",
        "num_files2 = len(files)\n",
        "print(\"Number of files:\", num_files2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgUIDC4Wqr8k",
        "outputId": "f607a0d3-717a-4a7d-9644-9afa58baea57"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files: 2551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the directory containing the spam files\n",
        "spam_directory = '/content/drive/MyDrive/spam_2'\n",
        "\n",
        "# Set the path to the directory containing the ham files\n",
        "ham_directory = '/content/drive/MyDrive/easy_ham'\n",
        "\n",
        "\n",
        "# Creating a function to read each file in the folder\n",
        "def read_emails(file_path, class_value):\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        lines = file.readlines()\n",
        "        text = ' '.join(lines)\n",
        "        return {'file': file_path, 'text': text, 'class': class_value, 'spam': int(class_value == 'spam')}\n",
        "\n",
        "# Getting Ham and Spam Files\n",
        "spam_files = [os.path.join(spam_directory, file) for file in os.listdir(spam_directory)]\n",
        "ham_files = [os.path.join(ham_directory, file) for file in os.listdir(ham_directory)]\n",
        "\n",
        "# Creating Dataframes\n",
        "spam_df = pd.DataFrame(map(partial(read_emails, class_value='spam'), spam_files))\n",
        "ham_df = pd.DataFrame(map(partial(read_emails, class_value='ham'), ham_files))\n",
        "emails = pd.DataFrame.append(spam_df, ham_df, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIZwOzkdrCpr",
        "outputId": "30beb36d-ce24-4430-d001-89f17f899cc2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-297b17b409ce>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  emails = DataFrame.append(spam_df, ham_df, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emails.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIJJxwezyNpk",
        "outputId": "7430e256-34aa-4eb7-da19-9c08ff73ff97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                    file  \\\n",
              "0     /content/drive/MyDrive/spam_2/00566.9b3e6f0ed5...   \n",
              "1     /content/drive/MyDrive/spam_2/00610.d78eda68ed...   \n",
              "2     /content/drive/MyDrive/spam_2/00311.176626eb0e...   \n",
              "3     /content/drive/MyDrive/spam_2/00314.ce1926a981...   \n",
              "4     /content/drive/MyDrive/spam_2/00496.acf53035be...   \n",
              "...                                                 ...   \n",
              "3943  /content/drive/MyDrive/easy_ham/0152.10d322018...   \n",
              "3944  /content/drive/MyDrive/easy_ham/1622.91772e8eb...   \n",
              "3945  /content/drive/MyDrive/easy_ham/0155.56e909508...   \n",
              "3946  /content/drive/MyDrive/easy_ham/1636.5583afc73...   \n",
              "3947  /content/drive/MyDrive/easy_ham/1561.b968a0929...   \n",
              "\n",
              "                                                   text class  spam  \n",
              "0     From egtan@yahoo.com  Mon Jun 24 17:51:57 2002...  spam     1  \n",
              "1     From moreinformation@btamail.net.cn  Mon Jun 2...  spam     1  \n",
              "2     From StopSearching@fuse.net  Mon Jun 24 17:03:...  spam     1  \n",
              "3     From christine@trafficmagnet.net  Mon Jun 24 1...  spam     1  \n",
              "4     From corina-toma@webmail.co.za  Mon Jun 24 17:...  spam     1  \n",
              "...                                                 ...   ...   ...  \n",
              "3943  From sentto-2242572-55941-1034006157-zzzz=exam...   ham     0  \n",
              "3944  From spamassassin-devel-admin@lists.sourceforg...   ham     0  \n",
              "3945  From sentto-2242572-55980-1034027115-zzzz=exam...   ham     0  \n",
              "3946  From spamassassin-devel-admin@lists.sourceforg...   ham     0  \n",
              "3947  From spamassassin-talk-admin@lists.sourceforge...   ham     0  \n",
              "\n",
              "[3948 rows x 4 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spamham = emails"
      ],
      "metadata": {
        "id": "90ijXITazOMU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the text column by removing line breaks and tabs from the different files\n",
        "spamham['text'] = spamham['text'].str.replace(r'[\\r\\n\\t]+', '')\n",
        "\n",
        "# Removing punctuation from the text columns\n",
        "spamham['text'] = spamham['text'].str.replace(r'[^\\w\\s]', ' ')\n",
        "\n",
        "# Cleaning data by removing common words, punctuation, and numbers from the text files of the emails\n",
        "corpus = spamham['text']\n",
        "corpus = corpus.str.lower()\n",
        "corpus = corpus.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
        "corpus = corpus.apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
        "corpus = corpus.apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "corpus = corpus.str.strip()\n",
        "\n",
        "# Creating a Document-Term Matrix (DTM) from the corpus object to represent the term frequency for the documents\n",
        "cv = CountVectorizer(min_df=0.1, max_df=0.9)\n",
        "dtm = cv.fit_transform(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF-QCGOmzIVz",
        "outputId": "2d9cf9fa-21bd-4f6f-d438-8c10be45208b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-2150d80667b1>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  spamham['text'] = spamham['text'].str.replace(r'[\\r\\n\\t]+', '')\n",
            "<ipython-input-44-2150d80667b1>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  spamham['text'] = spamham['text'].str.replace(r'[^\\w\\s]', ' ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Document-Term Matrix (DTM)\n",
        "cv = CountVectorizer()\n",
        "dtm = cv.fit_transform(corpus)\n",
        "terms = cv.get_feature_names_out()\n"
      ],
      "metadata": {
        "id": "_xcU0Aza3JHI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the DTM into a DataFrame\n",
        "email_dtm = pd.DataFrame(dtm.toarray(), columns= terms )\n",
        "email_dtm['class'] = spamham['class']\n",
        "email_dtm['class'] = pd.Categorical(email_dtm['class'])\n"
      ],
      "metadata": {
        "id": "_FnUBlYHKO7y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The training set will use 60% of the total rows and a higher row count crashed my computer\n",
        "sample_size = int(0.6 * email_dtm.shape[0])\n",
        "\n",
        "# Setting Seed for reproducibility\n",
        "np.random.seed(334)\n",
        "\n",
        "indices = np.random.choice(email_dtm.shape[0], size=sample_size, replace=False)\n",
        "\n",
        "# Categorize between the training and testing DTMs\n",
        "dtm_training = email_dtm.iloc[indices, :]\n",
        "dtm_testing = email_dtm.drop(indices, axis=0)\n",
        "\n",
        "# Training and Test Spam labels\n",
        "training_labels = dtm_training['class']\n",
        "testing_labels = dtm_testing['class']\n",
        "\n",
        "# Propotion between Ham and Spam Amount\n",
        "training_label_proportions = training_labels.value_counts(normalize=True)\n",
        "print(training_label_proportions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0H1HmMBLyIF",
        "outputId": "2ef96706-4951-42a3-d8d4-30c2c4bc46b4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham     0.647804\n",
            "spam    0.352196\n",
            "Name: class, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email_dtm.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ZuwtrcIhhs",
        "outputId": "8fef280f-66c8-4683-a9e3-490ec7f08daa"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['__', '___', '____', '_____', '______', '_______', '________',\n",
              "       '_________', '__________', '___________',\n",
              "       ...\n",
              "       'þày', 'þë', 'þö', 'þööööà', 'ÿò', 'ÿÿ', 'ÿÿã',\n",
              "       'ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿò',\n",
              "       'ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿô',\n",
              "       'ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿó'],\n",
              "      dtype='object', length=74364)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Occurrence Matrix to a binary matrix\n",
        "dtm_training.loc[:, 2:3816] = np.where(dtm_training.iloc[:,2:3816] == 0, \"No\", \"Yes\")\n",
        "dtm_testing.loc[:, 2:3816] = np.where(dtm_testing.iloc[:, 2:3816] == 0, \"No\", \"Yes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x6LvglcL_xe",
        "outputId": "557774a5-8921-41f1-b64f-6555d8e267f3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-caa0e18a9692>:2: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
            "  dtm_training.loc[:, 2:3816] = np.where(dtm_training.iloc[:,2:3816] == 0, \"No\", \"Yes\")\n",
            "<ipython-input-57-caa0e18a9692>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dtm_training.loc[:, 2:3816] = np.where(dtm_training.iloc[:,2:3816] == 0, \"No\", \"Yes\")\n",
            "<ipython-input-57-caa0e18a9692>:3: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
            "  dtm_testing.loc[:, 2:3816] = np.where(dtm_testing.iloc[:, 2:3816] == 0, \"No\", \"Yes\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtm_training_1 = dtm_training.replace({'Yes': 1, 'No': 0})\n",
        "dtm_testing_1 = dtm_testing.replace({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Naive Bayes Predictive Model\n",
        "model_classifier = MultinomialNB()\n",
        "model_classifier.fit(dtm_training_1.iloc[:, 2:3817].astype(int), training_labels)\n",
        "\n",
        "# Using model on the testing dataframe\n",
        "test_prediction = model_classifier.predict(dtm_testing_1.iloc[:, 2:3817].astype(int))\n",
        "\n",
        "# Performance of the prediction model\n",
        "cm = confusion_matrix(testing_labels, test_prediction, labels=[\"spam\", \"ham\"])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7_cfJFRTpjL",
        "outputId": "119bf665-24bf-4fa6-cd36-b92bfe9d88cc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[431 132]\n",
            " [ 26 991]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(testing_labels, test_prediction)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l35V-BnOUVaT",
        "outputId": "92bff43b-9fea-43e3-b39c-ccc6fabc8443"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n"
          ]
        }
      ]
    }
  ]
}